{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "directory_path = '/Volumes/group/LiDAR/LidarProcessing/changedetection_m3c2/grid_output/delmar_grid_run_20240927' # second run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_csv_files(directory, pattern=\"grid_1m.csv\", erosion=True):\n",
    "    \"\"\"\n",
    "    Traverse the given directory and find all CSV files that match the pattern.\n",
    "    If erosion=True, include files without 'acc' in the name.\n",
    "    If erosion=False, include only files with 'acc' in the name.\n",
    "    Return a sorted list of full file paths based on the dates in the filenames.\n",
    "    \"\"\"\n",
    "    csv_files = []\n",
    "    \n",
    "    # Regex pattern to extract date from the filename\n",
    "    date_pattern = re.compile(r\"(\\d{8})\")  # Looks for an 8-digit date (YYYYMMDD)\n",
    "\n",
    "    # Walk through the directory and subdirectories\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # Check if the file matches the conditions for erosion or acc\n",
    "            if erosion and \"acc\" not in file and file.endswith(pattern):\n",
    "                # Get the full path to the file\n",
    "                full_path = os.path.join(root, file)\n",
    "                \n",
    "                # Extract the date from the filename\n",
    "                match = date_pattern.search(file)\n",
    "                if match:\n",
    "                    date_str = match.group(1)  # Extract the first matched date\n",
    "                    csv_files.append((full_path, date_str))\n",
    "            elif not erosion and \"acc\" in file and file.endswith(pattern):\n",
    "                # Get the full path to the file\n",
    "                full_path = os.path.join(root, file)\n",
    "                \n",
    "                # Extract the date from the filename\n",
    "                match = date_pattern.search(file)\n",
    "                if match:\n",
    "                    date_str = match.group(1)  # Extract the first matched date\n",
    "                    csv_files.append((full_path, date_str))\n",
    "\n",
    "    # Sort the list of tuples (path, date) based on the date string\n",
    "    csv_files.sort(key=lambda x: x[1])  # Sort by the date part\n",
    "    \n",
    "    # Return only the paths, now sorted by date\n",
    "    return [file[0] for file in csv_files]\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------------------------------------------ # \n",
    "\n",
    "def load_csv_to_numpy(file_list):\n",
    "    \"\"\"\n",
    "    Given a list of CSV file paths, load them into a 3D NumPy array, ignoring row and column labels.\n",
    "    Each CSV is expected to have the same dimensions, but row and column labels should be ignored.\n",
    "    \n",
    "    Parameters:\n",
    "    file_list (list of str): List of file paths to the CSV files.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: A 3D NumPy array where each CSV is a 2D grid.\n",
    "    \"\"\"\n",
    "    grid_list = []\n",
    "    \n",
    "    for file in file_list:\n",
    "        # Load the CSV file into a pandas DataFrame\n",
    "        # We skip the first row (column labels) and treat the first column as row labels (index_col=0)\n",
    "        df = pd.read_csv(file, index_col=0, header=0)\n",
    "        \n",
    "        # Convert the DataFrame to a NumPy array and append to the list\n",
    "        grid_list.append(df.values)\n",
    "    \n",
    "    # Stack all the 2D grids into a 3D NumPy array\n",
    "    grid_3d = np.stack(grid_list, axis=0)\n",
    "    \n",
    "    return grid_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the cleaned csv files\n",
    "acc_grid_files_10x10cm_cleaned = find_csv_files(directory_path, pattern=\"acc_grid_cleaned.csv\", erosion=False)\n",
    "acc_cluster_files_10x10cm_cleaned = find_csv_files(directory_path, pattern=\"acc_clusters_cleaned.csv\", erosion=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the clusters to numpy arrays\n",
    "acc_clusters_10x10cm_cleaned = load_csv_to_numpy(acc_cluster_files_10x10cm_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the grids to numpy arrays\n",
    "acc_grids_10x10cm_cleaned = load_csv_to_numpy(acc_grid_files_10x10cm_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop them both and save \n",
    "acc_cropped_grid_cleaned = acc_grids_10x10cm_cleaned[:, 4745:27595, :]\n",
    "acc_cropped_clusters_cleaned = acc_clusters_10x10cm_cleaned[:, 4745:27595, :]\n",
    "\n",
    "np.savez(\"/Users/cjmack/Documents/Papers/Cliffs/Code/local_grids/cleaned/acc_grid_files_cleaned.npz\", data=acc_grid_files_10x10cm_cleaned)\n",
    "np.savez(\"/Users/cjmack/Documents/Papers/Cliffs/Code/local_grids/cleaned/acc_cluster_files_cleaned.npz\", data=acc_cluster_files_10x10cm_cleaned)\n",
    "np.savez(\"/Users/cjmack/Documents/Papers/Cliffs/Code/local_grids/cleaned/acc_cropped_grid_cleaned.npz\", data=acc_cropped_grid_cleaned)\n",
    "np.savez(\"/Users/cjmack/Documents/Papers/Cliffs/Code/local_grids/cleaned/acc_cropped_clusters_cleaned.npz\", data=acc_cropped_clusters_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for the erosion grids\n",
    "ero_grid_files_10x10cm_cleaned = find_csv_files(directory_path, pattern=\"ero_grid_cleaned.csv\", erosion=True)\n",
    "ero_cluster_files_10x10cm_cleaned = find_csv_files(directory_path, pattern=\"ero_clusters_cleaned.csv\", erosion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ero_clusters_10x10cm_cleaned = load_csv_to_numpy(ero_cluster_files_10x10cm_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ero_grids_10x10cm_cleaned = load_csv_to_numpy(ero_grid_files_10x10cm_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ero_cropped_grid_cleaned = ero_grids_10x10cm_cleaned[:, 4745:27595, :]\n",
    "ero_cropped_clusters_cleaned = ero_clusters_10x10cm_cleaned[:, 4745:27595, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"/Users/cjmack/Documents/Papers/Cliffs/Code/local_grids/cleaned/ero_grid_files_cleaned.npz\", data=ero_grid_files_10x10cm_cleaned)\n",
    "np.savez(\"/Users/cjmack/Documents/Papers/Cliffs/Code/local_grids/cleaned/ero_cluster_files_cleaned.npz\", data=ero_cluster_files_10x10cm_cleaned)\n",
    "np.savez(\"/Users/cjmack/Documents/Papers/Cliffs/Code/local_grids/cleaned/ero_cropped_grid_cleaned.npz\", data=ero_cropped_grid_cleaned)\n",
    "np.savez(\"/Users/cjmack/Documents/Papers/Cliffs/Code/local_grids/cleaned/ero_cropped_clusters_cleaned.npz\", data=ero_cropped_clusters_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m3c2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
